{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db59e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf69ca",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9bc4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectile_loss_fn(expectiles, taus, samples):\n",
    "    '''\n",
    "    From Nature Paper Online Code (their notes below)\n",
    "    It's the Expectile loss function for finding samples this time instead of expectiles.\n",
    "    see Rowland et al. 2019 eqn. 8\n",
    "\n",
    "    '''\n",
    "\n",
    "    # distributional TD model: delta_t = (r + \\gamma V*) - V_i\n",
    "    # expectile loss: delta = sample - expectile\n",
    "    delta = (samples[None, :] - expectiles[:, None])\n",
    "\n",
    "    # distributional TD model: alpha^+ delta if delta > 0, alpha^- delta otherwise\n",
    "    # expectile loss: |taus - I_{delta <= 0}| * delta^2\n",
    "\n",
    "    # Note: When used to decode we take the gradient of this loss,\n",
    "    # and then evaluate the mean-squared gradient. That is because *samples* must\n",
    "    # trade-off errors with all expectiles to zero out the gradient of the\n",
    "    # expectile loss.\n",
    "    indic = np.array(delta <= 0., dtype=np.float32)\n",
    "    grad =  np.abs(taus[:, None] - indic) * delta * -0.5\n",
    "    return np.mean(np.square(np.mean(grad, axis=-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a843343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_expectiles(expectiles0,taus,samples,method='optimize_scipy',alpha=0.01,\n",
    "                    max_iters=10000,precision=0.0001,printt=False):\n",
    "\n",
    "    '''\n",
    "    Given samples, calculate best fitting expectiles.\n",
    "\n",
    "    Notes on gradient descent:\n",
    "        - learning rate needs to be low (0.01 or less) for distributions with rare events\n",
    "        - in general, I don't the grad descent function, but it's nice to know it works\n",
    "\n",
    "    '''\n",
    "    if method=='grad_desc':\n",
    "        expectiles_n = expectiles0.copy()\n",
    "        for _i in range(max_iters):\n",
    "            if printt:\n",
    "                print(_i)\n",
    "            expectiles_c = expectiles_n\n",
    "\n",
    "            # grad over entire dataset (versus at a sample)\n",
    "            grad = np.mean(grad_expectile_loss(expectiles_c,taus,samples),axis=1)\n",
    "            expectiles_n = expectiles_c - alpha*np.squeeze(grad)\n",
    "\n",
    "            step = expectiles_c-expectiles_n\n",
    "            if np.all(np.abs(step)<=precision):\n",
    "                expectiles = expectiles_n\n",
    "                print('here')\n",
    "                break\n",
    "\n",
    "        expectiles = expectiles_n\n",
    "\n",
    "    elif method=='optimize_scipy':\n",
    "        #import pdb; pdb.set_trace()\n",
    "        fn_to_minimize = lambda x: expectile_loss(x, taus, samples)\n",
    "        result = scipy.optimize.minimize(\n",
    "                    fn_to_minimize, method=None, x0=expectiles0)['x']\n",
    "        expectiles = result\n",
    "\n",
    "    return(expectiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc94d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_distribution(expectiles, taus, minv=-10, maxv=10, method=None,\n",
    "                 max_samples=100, max_epochs=5, N=25):\n",
    "    \"\"\"\n",
    "    From Nature Paper Online Code (their notes below)\n",
    "    They say 'Run decoding given reversal points and asymmetries (taus).'\n",
    "\n",
    "    expectiles were reversal points in their code\n",
    "    Reversal points = (but they were estimated from neurons)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ind = list(np.argsort(expectiles))\n",
    "    points = expectiles[ind]\n",
    "    tau = taus[ind]\n",
    "\n",
    "    # Robustified optimization to infer distribution\n",
    "    # Generate max_epochs sets of samples,\n",
    "    # each starting the optimization at the best of max_samples initial points.\n",
    "    sampled_dist = []\n",
    "    for _ in range(max_epochs):\n",
    "        # Randomly search for good initial conditions\n",
    "        # This significantly improves the minima found\n",
    "        #import pdb; pdb.set_trace()\n",
    "        samples = np.random.uniform(minv, maxv, size=(max_samples, N))\n",
    "        fvalues = np.array([expectile_loss_fn(points, tau, x0) for x0 in samples])\n",
    "        #np.array([x0 for x0 in samples])\n",
    "\n",
    "        # Perform loss minimizing on expectile loss (w.r.t samples)\n",
    "        x0 = np.array(sorted(samples[fvalues.argmin()]))\n",
    "        fn_to_minimize = lambda x: expectile_loss_fn(points, tau, x)\n",
    "        result = scipy.optimize.minimize(\n",
    "            fn_to_minimize, method=method,\n",
    "            bounds=[(minv, maxv) for _ in x0], x0=x0)['x']\n",
    "\n",
    "        #import pdb; pdb.set_trace()\n",
    "        sampled_dist.extend(result.tolist())\n",
    "\n",
    "    return np.array(sampled_dist), expectile_loss_fn(points, tau, np.array(sampled_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187ce506",
   "metadata": {},
   "source": [
    "### Expectile Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "680d5977",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(0,1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27707fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_quantiles = 10\n",
    "taus = (2 * np.arange(n_quantiles) + 1) / (2.0 * n_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34bffc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_quantiles(x, taus):\n",
    "    quantiles = []\n",
    "    for tau in taus:\n",
    "        quantiles.append(np.quantile(x, tau))\n",
    "    return(np.array(quantiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7556b2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.64638609, -1.10887061, -0.73659993, -0.42748155, -0.15054027,\n",
       "        0.09400835,  0.39304641,  0.69622456,  1.0426685 ,  1.63792869])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_quantiles(x, taus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_expectiles(x, taus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a421a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a442a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
