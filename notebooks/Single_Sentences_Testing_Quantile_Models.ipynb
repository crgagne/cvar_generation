{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084e43d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import sys\n",
    "import imp\n",
    "sys.path.append('../')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c05b6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    GPT2Config,\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    MinLengthLogitsProcessor,\n",
    "    LogitsProcessorList,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from cvar_helpers import calc_cvar_from_quantiles\n",
    "from cvar_sampler import distort_probabilities\n",
    "from rl_learner import TD_Learner\n",
    "from generate_sentences_w_cvar import score_sentiment\n",
    "\n",
    "import manual_examples\n",
    "imp.reload(manual_examples)\n",
    "from manual_examples import get_probabilities, get_distributions, plot_distributions, get_prompt_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299af95",
   "metadata": {},
   "source": [
    "### Loading GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a7766e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = '../models/pretrained/gpt2-large/'\n",
    "config = GPT2Config.from_pretrained(modelname)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(modelname)\n",
    "model = GPT2LMHeadModel.from_pretrained(modelname)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4940c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_tokenizer = AutoTokenizer.from_pretrained('../models/pretrained/cardiffnlp-twitter-roberta-base-sentiment')\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained('../models/pretrained/cardiffnlp-twitter-roberta-base-sentiment')\n",
    "sentiment_model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be54fdc",
   "metadata": {},
   "source": [
    "### Loading RL Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c8c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rl_model(epoch=75, hidden_dim =104, n_quantiles = 10, extra = '_prompt_enc',\n",
    "                  folder = 'single_sentences_IYou_3',huber=0.1):\n",
    "\n",
    "    filename='../data/results/'+folder+'/'\n",
    "    filename+=f'quantile_learner_{hidden_dim}_{huber}{extra}/log_quantile_learner_epoch{epoch}.pkl'\n",
    "\n",
    "    Z_network = TD_Learner(config.n_embd, n_quantiles, hidden_dim=hidden_dim)\n",
    "    Z_network.load_state_dict(torch.load(filename.replace('log_',''),map_location=torch.device('cpu')))\n",
    "\n",
    "    log = pickle.load(open(filename,'rb'))\n",
    "    loss = np.array(log['loss'])\n",
    "    epoch = np.array(log['epoch'])\n",
    "    \n",
    "    taus = (2 * np.arange(n_quantiles) + 1) / (2.0 * n_quantiles)\n",
    "    alphas = np.append(np.insert(taus, 0, 0), 1) # add zero, one\n",
    "    \n",
    "    out = {'Z_network': Z_network,\n",
    "             'loss': loss,\n",
    "           'taus' : taus,\n",
    "          'log':log,\n",
    "          'epoch':epoch,\n",
    "          'alphas': alphas}\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39003ea4",
   "metadata": {},
   "source": [
    "### V3 w/ and w/o prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcc4afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = load_rl_model(epoch=75, hidden_dim =104, n_quantiles = 10, extra = '_prompt_enc',\n",
    "                  folder = 'single_sentences_IYou_3',huber=0.1)\n",
    "Z_network = out['Z_network']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06637406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I felt really sick.\n",
      "[-0.67 -0.72 -0.76 -0.78 -0.8  -0.81 -0.82 -0.83 -0.83 -0.72]\n",
      "[-0.9379235]\n",
      "\n",
      "I felt sick.\n",
      "[-0.56 -0.64 -0.69 -0.72 -0.75 -0.77 -0.79 -0.8  -0.81 -0.73]\n",
      "[-0.87500717]\n",
      "\n",
      "I felt somewhat sick.\n",
      "[-0.55 -0.62 -0.66 -0.7  -0.72 -0.75 -0.77 -0.78 -0.8  -0.71]\n",
      "[-0.89648049]\n",
      "\n",
      "I did not feel that sick.\n",
      "[-0.31 -0.26 -0.24 -0.23 -0.22 -0.2  -0.19 -0.17 -0.16 -0.14]\n",
      "[-0.58306157]\n",
      "\n",
      "I felt ok.\n",
      "[0.35 0.47 0.5  0.51 0.51 0.51 0.5  0.48 0.46 0.41]\n",
      "[0.85541132]\n",
      "\n",
      "I felt like I had a cold.\n",
      "[-0.52 -0.56 -0.59 -0.61 -0.62 -0.63 -0.64 -0.64 -0.64 -0.56]\n",
      "[-0.84604912]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prompt in ['I felt really sick.', 'I felt sick.', \n",
    "               'I felt somewhat sick.', 'I did not feel that sick.',\n",
    "               'I felt ok.',\n",
    "               'I felt like I had a cold.']:\n",
    "    \n",
    "    thetas, cvars = get_prompt_distribution(prompt, tokenizer, model, device, Z_network)\n",
    "    print(prompt)\n",
    "    print(np.round(thetas,2))\n",
    "    print(score_sentiment(prompt, sentiment_tokenizer, sentiment_model, device))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05d90920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was boring.\n",
      "[-0.3  -0.37 -0.41 -0.44 -0.47 -0.49 -0.51 -0.52 -0.54 -0.48]\n",
      "[-0.93666359]\n",
      "\n",
      "It was very boring.\n",
      "[-0.35 -0.39 -0.42 -0.45 -0.47 -0.48 -0.5  -0.51 -0.52 -0.47]\n",
      "[-0.96904829]\n",
      "\n",
      "It was extremely boring.\n",
      "[-0.48 -0.55 -0.6  -0.63 -0.66 -0.69 -0.71 -0.73 -0.75 -0.69]\n",
      "[-0.9732028]\n",
      "\n",
      "It was strenuous.\n",
      "[0.01 0.04 0.05 0.06 0.07 0.08 0.08 0.09 0.11 0.13]\n",
      "[-0.23800157]\n",
      "\n",
      "It was very strenuous.\n",
      "[-0.05 -0.01  0.01  0.02  0.03  0.05  0.06  0.07  0.1   0.14]\n",
      "[-0.3932954]\n",
      "\n",
      "It was extremely strenuous.\n",
      "[-0.02 -0.    0.01  0.01  0.02  0.02  0.03  0.04  0.05  0.07]\n",
      "[-0.5088403]\n",
      "\n",
      "It was hard.\n",
      "[-0.09 -0.07 -0.07 -0.06 -0.06 -0.06 -0.05 -0.04 -0.03  0.  ]\n",
      "[-0.44828964]\n",
      "\n",
      "It was very hard.\n",
      "[-0.13 -0.09 -0.08 -0.07 -0.06 -0.05 -0.04 -0.03 -0.01  0.04]\n",
      "[-0.68532158]\n",
      "\n",
      "It was extremely hard.\n",
      "[-0.1  -0.09 -0.09 -0.09 -0.09 -0.09 -0.09 -0.08 -0.08 -0.06]\n",
      "[-0.74546438]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prompt in ['It was boring.','It was very boring.', 'It was extremely boring.',\n",
    "               'It was strenuous.','It was very strenuous.', 'It was extremely strenuous.',\n",
    "              'It was hard.','It was very hard.', 'It was extremely hard.']:\n",
    "    \n",
    "    thetas, cvars = get_prompt_distribution(prompt, tokenizer, model, device, Z_network)\n",
    "    print(prompt)\n",
    "    print(np.round(thetas,2))\n",
    "    print(score_sentiment(prompt, sentiment_tokenizer, sentiment_model, device))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1698eef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will be bad.\n",
      "[-0.55 -0.6  -0.62 -0.64 -0.65 -0.66 -0.67 -0.67 -0.66 -0.55]\n",
      "[-0.86431855]\n",
      "\n",
      "It will be very bad.\n",
      "[-0.63 -0.62 -0.62 -0.62 -0.62 -0.62 -0.61 -0.6  -0.58 -0.5 ]\n",
      "[-0.92837798]\n",
      "\n",
      "It will be extremely bad.\n",
      "[-0.74 -0.72 -0.73 -0.73 -0.73 -0.72 -0.72 -0.71 -0.7  -0.62]\n",
      "[-0.94130034]\n",
      "\n",
      "It will be boring.\n",
      "[-0.08 -0.09 -0.1  -0.11 -0.12 -0.12 -0.13 -0.14 -0.14 -0.14]\n",
      "[-0.84792384]\n",
      "\n",
      "It will be very boring.\n",
      "[-0.22 -0.22 -0.22 -0.23 -0.23 -0.24 -0.24 -0.24 -0.24 -0.24]\n",
      "[-0.93431965]\n",
      "\n",
      "It will be extremely boring.\n",
      "[-0.39 -0.4  -0.42 -0.43 -0.43 -0.44 -0.45 -0.45 -0.45 -0.43]\n",
      "[-0.95319607]\n",
      "\n",
      "It will be strenuous.\n",
      "[-0.1  -0.05 -0.03 -0.02 -0.    0.01  0.02  0.03  0.05  0.08]\n",
      "[-0.24446443]\n",
      "\n",
      "It will be very strenuous.\n",
      "[-0.14 -0.1  -0.08 -0.06 -0.05 -0.04 -0.02 -0.01  0.01  0.05]\n",
      "[-0.41001865]\n",
      "\n",
      "It will be extremely strenuous.\n",
      "[-0.16 -0.12 -0.1  -0.09 -0.08 -0.07 -0.05 -0.04 -0.02  0.01]\n",
      "[-0.51264539]\n",
      "\n",
      "It will be hard.\n",
      "[-0.13 -0.09 -0.07 -0.06 -0.05 -0.04 -0.02 -0.01  0.01  0.04]\n",
      "[-0.54603691]\n",
      "\n",
      "It will be very hard.\n",
      "[-0.21 -0.15 -0.12 -0.1  -0.08 -0.06 -0.04 -0.02  0.01  0.07]\n",
      "[-0.76402141]\n",
      "\n",
      "It will be extremely hard.\n",
      "[-0.29 -0.24 -0.22 -0.21 -0.19 -0.18 -0.16 -0.14 -0.12 -0.08]\n",
      "[-0.78547171]\n",
      "\n",
      "It will be difficult.\n",
      "[-0.16 -0.12 -0.1  -0.09 -0.08 -0.07 -0.06 -0.05 -0.04 -0.02]\n",
      "[-0.55771812]\n",
      "\n",
      "It will be very difficult.\n",
      "[-0.23 -0.17 -0.14 -0.13 -0.11 -0.09 -0.07 -0.05 -0.02  0.03]\n",
      "[-0.75575143]\n",
      "\n",
      "It will be extremely difficult.\n",
      "[-0.28 -0.23 -0.21 -0.2  -0.19 -0.18 -0.17 -0.16 -0.14 -0.1 ]\n",
      "[-0.78240292]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prompt in ['It will be bad.','It will be very bad.', 'It will be extremely bad.',\n",
    "                'It will be boring.','It will be very boring.', 'It will be extremely boring.',\n",
    "               'It will be strenuous.','It will be very strenuous.', 'It will be extremely strenuous.',\n",
    "              'It will be hard.','It will be very hard.', 'It will be extremely hard.',\n",
    "              'It will be difficult.','It will be very difficult.', 'It will be extremely difficult.']:\n",
    "    \n",
    "    thetas, cvars = get_prompt_distribution(prompt, tokenizer, model, device, Z_network)\n",
    "    print(prompt)\n",
    "    print(np.round(thetas,2))\n",
    "    print(score_sentiment(prompt, sentiment_tokenizer, sentiment_model, device))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784384f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
